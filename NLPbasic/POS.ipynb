{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# jieba词性标注（part of specch)\n",
    "#### 安装：pip install jieba\n",
    "#### 国内源安装更快：pip install jieba -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 先导包：jieba.posseg.dt 为默认词性标注分词器\n",
    "#### 标注句子分词后每个词的词性，采用和 ictclas 兼容的标记法。\n",
    "#### jieba貌似不能处理英文，后面会介绍处理英文的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我 r\n",
      "爱 v\n",
      "自然语言 l\n",
      "处理 v\n",
      "技术 n\n",
      "！ x\n"
     ]
    }
   ],
   "source": [
    "import jieba.posseg as pseg\n",
    "words = pseg.cut(\"我爱自然语言处理技术！\")\n",
    "for word, pos in words:\n",
    "    print(word, pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SnowNLP词性标注\n",
    "#### 安装：pip install snownlp \n",
    "#### 国内源安装：pip install snownlp  -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用snownlp进行词性标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我 r\n",
      "爱 v\n",
      "自然 n\n",
      "语言 n\n",
      "处理 vn\n",
      "技术 n\n",
      "！ w\n"
     ]
    }
   ],
   "source": [
    "from snownlp import SnowNLP\n",
    "model = SnowNLP(u'我爱自然语言处理技术！')\n",
    "for word, pos in model.tags:\n",
    "    print(word, pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THULAC词性标注\n",
    "#### 安装：pip install thulac    \n",
    "#### 国内源安装：pip install thulac     -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用thulac进行词性标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded succeed\n",
      "[['我', 'r'], ['爱', 'v'], ['自然', 'n'], ['语言', 'n'], ['处理', 'v'], ['技术', 'n'], ['！', 'w']]\n"
     ]
    }
   ],
   "source": [
    "import thulac\n",
    "thulac_model = thulac.thulac()\n",
    "wordseg = thulac_model.cut(\"我爱自然语言处理技术！\")\n",
    "print(wordseg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stanford CoreNLP分词\n",
    "#### 安装：pip install stanfordcorenlp    \n",
    "#### 国内源安装：pip install stanfordcorenlp -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用stanfordcorenlp进行词性标注\n",
    "#### 同时支持英文和中文的词性标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('我爱', 'NN'), ('自然', 'AD'), ('语言', 'NN'), ('处理', 'VV'), ('技术', 'NN'), ('！', 'PU')]\n"
     ]
    }
   ],
   "source": [
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "zh_model = StanfordCoreNLP(r'stanford-corenlp-full-2018-02-27', lang='zh')\n",
    "s_zh = '我爱自然语言处理技术！'\n",
    "word_pos_zh = zh_model.pos_tag(s_zh)\n",
    "print(word_pos_zh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP'), ('love', 'VBP'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('technology', 'NN'), ('!', '.')]\n"
     ]
    }
   ],
   "source": [
    "eng_model = StanfordCoreNLP(r'stanford-corenlp-full-2018-02-27')\n",
    "s_eng = 'I love natural language processing technology!'\n",
    "word_pos_eng = eng_model.pos_tag(s_eng)\n",
    "print(word_pos_eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hanlp词性标注\n",
    "#### 安装：pip install pyhanlp     \n",
    "#### 国内源安装：pip install pyhanlp  -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用pyhanlp进行词性标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我 rr\n",
      "爱 v\n",
      "自然语言处理 nz\n",
      "技术 n\n",
      "！ w\n"
     ]
    }
   ],
   "source": [
    "from pyhanlp import *\n",
    "s = '我爱自然语言处理技术！'\n",
    "word_seg = HanLP.segment(s)\n",
    "for term in word_seg:\n",
    "    print(term.word, term.nature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK词性标注\n",
    "#### 安装：pip install nltk     \n",
    "#### 国内源安装：pip install nltk  -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nltk只能处理英文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP'), ('love', 'VBP'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('technology', 'NN'), ('!', '.')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "s = 'I love natural language processing technology!'\n",
    "s = nltk.word_tokenize(s)\n",
    "s_pos = nltk.pos_tag(s)\n",
    "print(s_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spaCy词性标注\n",
    "#### 安装：pip install spaCy     \n",
    "#### 国内源安装：pip install spaCy  -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下载不了模型，需要python -m spacy download en。\n",
    "The easiest solution is to re-run the command as admin(意思是用用户管理权限打开CMD下载即可)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eng_model = spacy.load('en')\n",
    "s = 'I love natural language processing technology!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 词性标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I PRON 94\n",
      "love VERB 99\n",
      "natural ADJ 83\n",
      "language NOUN 91\n",
      "processing NOUN 91\n",
      "technology NOUN 91\n",
      "! PUNCT 96\n"
     ]
    }
   ],
   "source": [
    "s_token = eng_model(s)\n",
    "for token in s_token:\n",
    "    print(token, token.pos_, token.pos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
